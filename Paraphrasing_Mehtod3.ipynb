{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paraphrasing-Mehtod3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lalfxz3340Pw",
        "colab_type": "code",
        "outputId": "51fe6310-f04f-4c50-c953-58203877b7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## import libraries \n",
        "from keras.layers import Dense,LSTM,Embedding,GRU,Input,Dropout,RepeatVector,Flatten\n",
        "from keras.models import Sequential,Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "import keras.utils as KU\n",
        "import traceback\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "import keras.losses as KL\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As6fJ3-zigbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words=1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tII27sPr5Gkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##read dataset\n",
        "with open('quora_duplicate_questions.tsv',encoding=\"utf-8\") as f:\n",
        "  data=f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4iMTDlV5S8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus=[]\n",
        "for i in data:\n",
        "  line=i.split('\\t')\n",
        "  if(i!= \" \" and len(line)>5):\n",
        "    is_duplicate=line[5]\n",
        "    if(is_duplicate=='1'):\n",
        "        corpus.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LOQJ8qH5W3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts=[]\n",
        "target_texts=[]\n",
        "input_characters=set()\n",
        "target_characters=set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JWId_6u5Y1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Not create input text as English and output text as Hindi\n",
        "try:\n",
        "  for line in corpus[:10000]:\n",
        "      ##print(line)\n",
        "      if(line !=\"\"):\n",
        "          text=line.split('\\t')\n",
        "          input_text=text[3]\n",
        "          target_text=text[4]\n",
        "          input_texts.append(input_text.lower())\n",
        "          target_text='ssss '+target_text.lower()+' eeee'\n",
        "          ##print(target_text)\n",
        "          target_texts.append(target_text)\n",
        "          for char in input_text:\n",
        "              if char not in input_characters:\n",
        "                  input_characters.add(char)\n",
        "              \n",
        "          for char in target_text:\n",
        "              if char not in target_characters:\n",
        "                  target_characters.add(char)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  traceback.print_exc()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm7-U-ky5bju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sequence_len_input = max([len(x) for x in input_texts])\n",
        "max_sequence_len_target = max([len(x) for x in target_texts])\n",
        "\n",
        "input_tokenizer=Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "input_tokenizer.fit_on_texts(input_texts)\n",
        "\n",
        "target_tokenizer=Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "target_tokenizer.fit_on_texts(target_texts)\n",
        "\n",
        "input_vocab_size=len(input_tokenizer.word_index)+1\n",
        "target_vocab_size=len(target_tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl24XhqU5fI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## Now Generate the embeddings from Glove vector\n",
        "embeddings_index={}\n",
        "def Generate_Embeddings():\n",
        "    f=open('../content/glove.6B.100d.txt') \n",
        "    for line in f:\n",
        "        #print(line)\n",
        "        values=line.split()\n",
        "        word=values[0]\n",
        "        coefs=np.array(values[1:],dtype=\"float32\")\n",
        "        embeddings_index[word]=coefs\n",
        "    f.close()\n",
        "\n",
        "## Now Generate Metrix of embedding as per our data\n",
        "embedding_matrix = np.zeros((input_vocab_size, 100))\n",
        "def Generate_Embeddings_Matrix():\n",
        "    for word, i in input_tokenizer.word_index.items():\n",
        "        #print(word,\":::\",i)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9gzRFL05thR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generate_Embeddings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrEUWhxO53gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kahBofO5vvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "encoder_input_data=encode_sequences(input_tokenizer,max_sequence_len_input,input_texts)\n",
        "decoder_input_data=encode_sequences(target_tokenizer,max_sequence_len_target,target_texts)\n",
        "decoder_input_data_final=decoder_input_data[:,:-1]\n",
        "decoder_target_data=decoder_input_data[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNfosLd9B5vx",
        "colab_type": "code",
        "outputId": "76673654-e6c4-46ca-985c-4100ee5d1e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "## create an encoder archetecture\n",
        "encoder_input=Input(shape=(None,))\n",
        "encoder_embeddings=Embedding(input_vocab_size, 100, input_length=max_sequence_len_input-1, mask_zero=True,trainable=False)\n",
        "encoder_gru_1=GRU(512,name=\"encoder_gru_1\",return_sequences=True)\n",
        "encoder_gru_2=GRU(512,name=\"encoder_gru_2\",return_sequences=True)\n",
        "encoder_gru_3=GRU(512,name=\"encoder_gru_3\",return_sequences=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0712 10:12:01.270819 139780771780480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0712 10:12:01.307568 139780771780480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmDCnWUQELq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Create_Encoder():\n",
        "  #Here we will use functional api of keras\n",
        "  net=encoder_input\n",
        "  net=encoder_embeddings(net)\n",
        "  ## not need to connect GRU units\n",
        "  net=encoder_gru_1(net)\n",
        "  net=encoder_gru_2(net)\n",
        "  net=encoder_gru_3(net)\n",
        "  \n",
        "  return net\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv0-44D0FLl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Now create decoder architecture\n",
        "decoder_initial_state=Input(shape=(512,),name=\"decoder_initial_state\")\n",
        "decoder_input=Input(shape=(None,),name=\"decoder_input\")\n",
        "decoder_embeddings=Embedding(target_vocab_size, 100, input_length=max_sequence_len_target-1,trainable=False)\n",
        "decoder_gru_1=GRU(512,name=\"decoder_gru_1\",return_sequences=True)\n",
        "decoder_gru_2=GRU(512,name=\"decoder_gru_2\",return_sequences=True)\n",
        "decoder_gru_3=GRU(512,name=\"decoder_gru_3\",return_sequences=True)\n",
        "decoder_dense=Dense(target_vocab_size,activation=\"linear\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk9-AHgoGmZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Create_Decoder(initial_state):\n",
        "  #Here we will use functional api of keras\n",
        "  net=decoder_input\n",
        "  net=decoder_embeddings(net)\n",
        "  ## not need to connect GRU units\n",
        "  net=decoder_gru_1(net,initial_state=initial_state)\n",
        "  net=decoder_gru_2(net,initial_state=initial_state)\n",
        "  net=decoder_gru_3(net,initial_state=initial_state)\n",
        "  net=decoder_dense(net)\n",
        "  \n",
        "  return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgmRtZR0H8JP",
        "colab_type": "code",
        "outputId": "57d3f42c-b33a-4b55-bf9a-928dc2fef139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "##Create a Training Model\n",
        "encoder_output=Create_Encoder()\n",
        "decoder_output=Create_Decoder(encoder_output)\n",
        "model_train=Model(inputs=[encoder_input,decoder_input],outputs=[decoder_output])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0712 10:12:08.180418 139780771780480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0712 10:12:08.754595 139780771780480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GTfWIftIuO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create an Encoder Model\n",
        "model_encoder=Model(inputs=[encoder_input],outputs=[encoder_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX4W133MI-08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create a decoder model\n",
        "decoder_output=Create_Decoder(decoder_initial_state)\n",
        "model_decoder=Model(inputs=[decoder_input,decoder_initial_state],outputs=[decoder_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8GPdWhHJ5Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=optimizers.RMSprop(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KO1ixAdKswi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_target=tf.placeholder(dtype='int32',shape=(None,None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyKqhVOFK17m",
        "colab_type": "code",
        "outputId": "54922bc5-176f-42e4-9922-f01ad5717f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "model_train.compile(optimizer=optimizer, loss=KL.sparse_categorical_crossentropy,metrics=['acc'])\n",
        "model_train.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0712 10:12:31.899124 139780771780480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0712 10:12:31.911848 139780771780480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 147, 100)     234700      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_gru_1 (GRU)             (None, 147, 512)     941568      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder_input (InputLayer)      (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_gru_2 (GRU)             (None, 147, 512)     1574400     encoder_gru_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 205, 100)     237600      decoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_gru_3 (GRU)             (None, 512)          1574400     encoder_gru_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_gru_1 (GRU)             (None, 205, 512)     941568      embedding_2[0][0]                \n",
            "                                                                 encoder_gru_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_gru_2 (GRU)             (None, 205, 512)     1574400     decoder_gru_1[0][0]              \n",
            "                                                                 encoder_gru_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_gru_3 (GRU)             (None, 205, 512)     1574400     decoder_gru_2[0][0]              \n",
            "                                                                 encoder_gru_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 205, 2376)    1218888     decoder_gru_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 9,871,924\n",
            "Trainable params: 9,399,624\n",
            "Non-trainable params: 472,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGI1VXpAchN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_checkpoint='21_checkpoint.keras'\n",
        "callback_checkpoint=ModelCheckpoint(filepath=path_checkpoint,monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True)\n",
        "callback_earlystopping=EarlyStopping(monitor='val_loss',verbose=1,patience=3)\n",
        "callback_tensorboard=TensorBoard(log_dir='../content/21_logs/',histogram_freq=0,write_graph=False)\n",
        "callbacks=[callback_checkpoint,callback_earlystopping,callback_tensorboard]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF1GVOAwgPka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data={\n",
        "    'encoder-input':encoder_input_data,\n",
        "    'decoder-input':decoder_input_data\n",
        "}\n",
        "y_data={\n",
        "    'decoder_output':decoder_target_data\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwp6FPZCeQZE",
        "colab_type": "code",
        "outputId": "8137dae4-9c41-475d-a7fd-c504efeabd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "model_train.fit([encoder_input_data, decoder_input_data], decoder_target_data.reshape(10000, 269,1),\n",
        "          batch_size=640,\n",
        "          epochs=20,\n",
        "          validation_split=0.3,callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-948fa3a3c44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_train.fit([encoder_input_data, decoder_input_data], decoder_target_data.reshape(10000, 269,1),\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           validation_split=0.3,callbacks=callbacks)\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 410000 into shape (10000,269,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt-iKtBa5-sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_train.save('ModelNew.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9aBIUTvf1pD",
        "colab_type": "code",
        "outputId": "1236e150-5b94-449a-dfdb-6031d2d9b4c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_target_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 269)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZTISL6PlV9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}